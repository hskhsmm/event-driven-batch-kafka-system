
# Event-driven Batch & Kafka System

##  프로젝트 소개

이 프로젝트는
**순간적으로 폭증하는 사용자 이벤트를 안전하게 처리하기 위해
Kafka와 Spring Batch를 “올바른 역할”로 분리 적용한 백엔드 중심 실험 프로젝트**입니다.

다음 질문에 답하는 것을 목표로 합니다.

* 언제 Kafka를 써야 하는가?
* 언제 Batch를 쓰면 안 되는가?
* 동시성 문제를 서버가 아닌 어디에 맡겨야 하는가?
* 트랜잭션과 인덱스는 어떤 지점에서 필요한가?

---

##  프로젝트 목표

* **트래픽 폭증 상황을 의도적으로 만들어 테스트**
* Kafka가 없는 구조의 한계를 직접 확인
* Kafka + 단일 Consumer 구조로 **순서 보장과 중복 방지** 증명
* 지연 허용 가능한 집계를 **Spring Batch로 분리**
* “기술을 써봤다”가 아니라 **“써야 할 이유가 있었다”를 코드로 설명**

---

##  핵심 시나리오

### 선착순 캠페인 처리

* 다수의 사용자가 동시에 캠페인 참여 요청
* 총 수량 초과 발급 ❌
* 중복 발급 ❌
* 요청 폭증 시에도 시스템 안정성 유지 ⭕

---

##  시스템 아키텍처 개요

```
Client
  ↓
Spring Boot API
  ↓
Kafka
  ↓                ↓
Stats Consumer   First-Come Consumer
  ↓                    ↓
RDB (통계 원본)   RDB (조건부 UPDATE)
  ↓
Spring Batch
```

---

## ☁️ 클라우드 아키텍처 (AWS)

| 구성 요소                    | 사용 이유                            |
| ------------------------ | -------------------------------- |
| **EC2**                  | Kafka, API, Consumer를 직접 제어하기 위함 |
| **ALB**                  | Blue–Green 배포 및 트래픽 전환           |
| **RDS (MySQL)**          | 트랜잭션 기반 정합성 보장                   |
| **VPC / Security Group** | 네트워크 접근 범위 명확화                   |


---

##  백엔드 기술 스택 & 선택 이유

### Spring Boot

* 빠른 초기 세팅
* 트랜잭션/배치/Kafka 통합에 적합
* 실무 표준에 가까운 프레임워크

---

### MySQL (RDS)

| 사용 이유                    |
| ------------------------ |
| 조건부 UPDATE를 통한 원자적 수량 차감 |
| 인덱스 + 트랜잭션 학습에 최적        |
| 선착순 로직의 정합성 증명 가능        |

---

### Kafka

| Kafka를 사용한 이유         |
| --------------------- |
| 순간 트래픽 흡수             |
| 순서 보장 (partition = 1) |
| API 서버와 처리 로직 분리      |
| 서버 확장 시에도 중복 처리 방지    |

> 선착순 판단을
> **서버 인스턴스가 아니라 Kafka 파티션 순서에 위임**했습니다.

---

### Spring Batch

| Batch의 역할     |
| ------------- |
| 캠페인 결과 집계     |
| 일/시간 단위 통계 처리 |
| 실시간 트랜잭션과 분리  |

> 실시간 처리 흐름에 Batch를 섞지 않는 것을
> 명확한 설계 원칙으로 삼았습니다.

---

##  트랜잭션 & 동시성 처리 전략

```sql
UPDATE campaign
SET remaining_quantity = remaining_quantity - 1
WHERE id = ?
  AND remaining_quantity > 0;
```

* 영향을 받은 row = 1 → 발급 성공
* 0 → SOLD OUT
* 트랜잭션 단위로 실행

👉 서버 단에서 동기 락 처리 ❌
👉 **DB + Kafka Consumer 단에서 순차 처리 ⭕**

---

##  트래픽 폭증 테스트

### 테스트 목적

* Kafka 없이 처리 시 발생 가능한 문제 확인
* Kafka 도입 후 안정성 비교

### 테스트 도구

* **k6** (또는 JMeter)

### 테스트 조건

* 동시 사용자: 100명
* 요청 시간: 1초
* 발급 수량: 50개

### 기대 결과

* 성공 발급: 50
* 실패(SOLD_OUT): 50
* **중복 발급: 0**

---

## 제외한 기술

| 기술            | 제외 이유           |
| ------------- | --------------- |
| Elasticsearch | 검색이 핵심 문제가 아님   |
| Redis         | Kafka와 역할 중복    |
| MSK           | 운영 복잡도 대비 효과 낮음 |
| Auto Scaling  | 문제 정의 범위 초과     |
| 프론트엔드         | 백엔드 처리 흐름 집중    |

---

##  이 프로젝트가 증명하는 것

* Kafka와 Batch를 **구분해서 사용한 판단력**
* 트랜잭션과 동시성에 대한 이해
* “많이 쓴 기술”이 아닌 **“필요한 기술만 쓴 설계”**
* 트래픽 기반 문제를 테스트로 증명한 경험

---

이 프로젝트는
“화려한 서비스”가 아니라
**엔터프라이즈 백엔드에서 중요한 판단 능력**을 보여주기 위한 구조입니다.


오늘 어디까지 이어서 해볼까요?
