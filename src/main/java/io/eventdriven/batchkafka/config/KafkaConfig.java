package io.eventdriven.batchkafka.config;

import lombok.extern.slf4j.Slf4j;
import org.apache.kafka.clients.admin.AdminClient;
import org.apache.kafka.clients.admin.DescribeTopicsResult;
import org.apache.kafka.clients.admin.TopicDescription;
import org.apache.kafka.clients.consumer.ConsumerConfig;
import org.apache.kafka.clients.producer.ProducerConfig;
import org.apache.kafka.common.serialization.StringDeserializer;
import org.apache.kafka.common.serialization.StringSerializer;
import org.springframework.beans.factory.annotation.Value;
import org.springframework.context.annotation.Bean;
import org.springframework.context.annotation.Configuration;
import org.springframework.kafka.config.ConcurrentKafkaListenerContainerFactory;
import org.springframework.kafka.core.ConsumerFactory;
import org.springframework.kafka.core.DefaultKafkaConsumerFactory;
import org.springframework.kafka.core.DefaultKafkaProducerFactory;
import org.springframework.kafka.core.KafkaTemplate;
import org.springframework.kafka.annotation.EnableKafka;
import org.springframework.kafka.core.ProducerFactory;

import java.util.Collections;
import java.util.HashMap;
import java.util.Map;

@Slf4j
@EnableKafka
@Configuration
public class KafkaConfig {

    @Value("${spring.kafka.bootstrap-servers}")
    private String bootstrapServers;

    public static final String TOPIC_NAME = "campaign-participation-topic";

    /**
     * Kafka Admin ì„¤ì • - ì£¼ì„ ì²˜ë¦¬ (íŒŒí‹°ì…˜ ìˆ˜ë™ ê´€ë¦¬ë¡œ ë³€ê²½)
     * kafka-clients 4.1.1ì˜ AdminClient OAuth ë²„ê·¸ë¡œ ì¸í•´ ìë™ íŒŒí‹°ì…˜ ê´€ë¦¬ ë¹„í™œì„±í™”
     * íŒŒí‹°ì…˜ì€ Docker ëª…ë ¹ì–´ë¡œ ìˆ˜ë™ ê´€ë¦¬:
     * docker exec kafka kafka-topics --bootstrap-server kafka:29092 --alter --topic campaign-participation-topic --partitions <ê°œìˆ˜>
     */
    // @Bean
    // public KafkaAdmin kafkaAdmin() {
    //     Map<String, Object> configs = new HashMap<>();
    //     configs.put("bootstrap.servers", bootstrapServers);
    //     configs.put("security.protocol", "PLAINTEXT");
    //     return new KafkaAdmin(configs);
    // }

    /**
     * Kafka Producer ì„¤ì •
     * - Key: String (Campaign ID ë“±)
     * - Value: String (JSON ë¬¸ìì—´)
     * - ì‹ ë¢°ì„± ì„¤ì • ì¶”ê°€ (acks=all, idempotence=true)
     */
    @Bean
    public ProducerFactory<String, String> producerFactory() {
        Map<String, Object> configProps = new HashMap<>();
        configProps.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, bootstrapServers);
        configProps.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class);
        configProps.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class);

        // ì‹ ë¢°ì„± ë° ìˆœì„œ ë³´ì¥ì„ ìœ„í•œ ì„¤ì •
        configProps.put(ProducerConfig.ACKS_CONFIG, "all"); // ëª¨ë“  ë¦¬í”Œë¦¬ì¹´ ìŠ¹ì¸ ëŒ€ê¸°
        configProps.put(ProducerConfig.ENABLE_IDEMPOTENCE_CONFIG, true); // ë©±ë“±ì„± ë³´ì¥ (ì¤‘ë³µ ë°©ì§€)
        configProps.put(ProducerConfig.RETRIES_CONFIG, Integer.MAX_VALUE); // ì‹¤íŒ¨ ì‹œ ë¬´í•œ ì¬ì‹œë„

        // ì„±ëŠ¥ ìµœì í™” ì„¤ì • (t3.large 8GB, 10ë§Œ íŠ¸ë˜í”½ ì²˜ë¦¬ ìµœì í™”)
        configProps.put(ProducerConfig.BUFFER_MEMORY_CONFIG, 128 * 1024 * 1024); // 128MB (ë²„í¼ ì¦ê°€ë¡œ ëŒ€ê¸° ê°ì†Œ)
        configProps.put(ProducerConfig.BATCH_SIZE_CONFIG, 64 * 1024);           // 64KB (ë°°ì¹˜ í¬ê¸° ì¦ê°€)
        configProps.put(ProducerConfig.LINGER_MS_CONFIG, 20);                   // 20ms (ë°°ì¹˜ íš¨ìœ¨ ê·¹ëŒ€í™”, ì§€ì—° ìµœì†Œ)
        configProps.put(ProducerConfig.COMPRESSION_TYPE_CONFIG, "none");        // ì••ì¶• í•´ì œ (CPU ë¶€ë‹´ ì œê±°)
        configProps.put(ProducerConfig.MAX_BLOCK_MS_CONFIG, 60000);             // 60ì´ˆ ëŒ€ê¸° (íƒ€ì„ì•„ì›ƒ ë°©ì§€)

        return new DefaultKafkaProducerFactory<>(configProps);
    }

    @Bean
    public KafkaTemplate<String, String> kafkaTemplate() {
        return new KafkaTemplate<>(producerFactory());
    }

    /**
     * í† í”½ ìë™ ìƒì„± ì„¤ì • ì œê±°
     * - ì´ìœ : íŒŒí‹°ì…˜ ìˆ˜ë¥¼ ë™ì ìœ¼ë¡œ ê´€ë¦¬í•˜ê¸° ìœ„í•´ KafkaTopicServiceì—ì„œ ì²˜ë¦¬
     * - KafkaTopicService.ensurePartitions()ì—ì„œ í† í”½ ìƒì„± ë° íŒŒí‹°ì…˜ ì¦ê°€ë¥¼ ì²˜ë¦¬
     */
    // @Bean ì œê±°: ë™ì  íŒŒí‹°ì…˜ ê´€ë¦¬ë¥¼ ìœ„í•´ í† í”½ ìë™ ìƒì„± ë¹„í™œì„±í™”
    // public NewTopic campaignParticipationTopic() {
    //     return TopicBuilder.name(TOPIC_NAME)
    //             .partitions(1)
    //             .replicas(1)
    //             .build();
    // }

    /**
     * Kafka Consumer ì„¤ì •
     * - Key: String
     * - Value: String (JSON ë¬¸ìì—´)
     * - ìˆœì„œ ë³´ì¥ì„ ìœ„í•´ ë‹¨ì¼ Consumerë¡œ ì„¤ì •
     */
    @Bean
    public ConsumerFactory<String, String> consumerFactory() {
        Map<String, Object> configProps = new HashMap<>();
        configProps.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, bootstrapServers);
        configProps.put(ConsumerConfig.GROUP_ID_CONFIG, "campaign-participation-group");
        configProps.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class);
        configProps.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class);

        // ì„±ëŠ¥ ìµœì í™”ë¥¼ ìœ„í•´ í•œ ë²ˆì— ì—¬ëŸ¬ ë ˆì½”ë“œë¥¼ ê°€ì ¸ì˜¤ë„ë¡ ì„¤ì •
        configProps.put(ConsumerConfig.MAX_POLL_RECORDS_CONFIG, 500); // í•œ ë²ˆì— 500ê°œì”© ì²˜ë¦¬ (ë°°ì¹˜ í¬ê¸° ì¦ê°€)
        configProps.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, false); // ìˆ˜ë™ ì»¤ë°‹ (ì²˜ë¦¬ ì™„ë£Œ í›„ ì»¤ë°‹)
        configProps.put(ConsumerConfig.MAX_POLL_INTERVAL_MS_CONFIG, 600000); // 10ë¶„ (íƒ€ì„ì•„ì›ƒ ë°©ì§€)
        configProps.put(ConsumerConfig.SESSION_TIMEOUT_MS_CONFIG, 45000); // 45ì´ˆ (ì„¸ì…˜ íƒ€ì„ì•„ì›ƒ)

        return new DefaultKafkaConsumerFactory<>(configProps);
    }

    @Bean
    public ConcurrentKafkaListenerContainerFactory<String, String> kafkaListenerContainerFactory() {
        ConcurrentKafkaListenerContainerFactory<String, String> factory =
                new ConcurrentKafkaListenerContainerFactory<>();
        factory.setConsumerFactory(consumerFactory());
        factory.setBatchListener(true); // ğŸ‘ˆ ë°°ì¹˜ ë¦¬ìŠ¤ë„ˆ í™œì„±í™”

        // í† í”½ì˜ íŒŒí‹°ì…˜ ìˆ˜ë¥¼ ìë™ ê°ì§€í•´ì„œ concurrency ì„¤ì •
        int partitionCount = getTopicPartitionCount(TOPIC_NAME);
        factory.setConcurrency(partitionCount); // íŒŒí‹°ì…˜ ìˆ˜ë§Œí¼ Consumer ìŠ¤ë ˆë“œ ìƒì„±

        factory.getContainerProperties().setAckMode(
                org.springframework.kafka.listener.ContainerProperties.AckMode.MANUAL); // ìˆ˜ë™ ì»¤ë°‹
        return factory;
    }

    /**
     * Kafka í† í”½ì˜ íŒŒí‹°ì…˜ ìˆ˜ë¥¼ ìë™ ê°ì§€ (ì¬ì‹œë„ í¬í•¨)
     * Docker ëª…ë ¹ì–´ë¡œ íŒŒí‹°ì…˜ ìˆ˜ë¥¼ ë³€ê²½í•˜ë©´ ìë™ìœ¼ë¡œ ê°ì§€ë¨:
     * docker exec kafka kafka-topics --bootstrap-server kafka:29092 --alter --topic campaign-participation-topic --partitions 3
     */
    private int getTopicPartitionCount(String topicName) {
        int maxRetries = 5;
        int retryDelayMs = 2000;

        for (int retry = 0; retry < maxRetries; retry++) {
            try {
                Map<String, Object> configs = new HashMap<>();
                configs.put("bootstrap.servers", bootstrapServers);

                try (AdminClient adminClient = AdminClient.create(configs)) {
                    DescribeTopicsResult result = adminClient.describeTopics(Collections.singletonList(topicName));
                    Map<String, TopicDescription> descriptions = result.allTopicNames().get(5, java.util.concurrent.TimeUnit.SECONDS);
                    TopicDescription description = descriptions.get(topicName);

                    if (description == null) {
                        log.warn("âš ï¸ í† í”½ '{}' ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì¬ì‹œë„ {}/{}", topicName, retry + 1, maxRetries);
                        Thread.sleep(retryDelayMs);
                        continue;
                    }

                    int partitionCount = description.partitions().size();

                    log.info("ğŸ”§ Kafka í† í”½ '{}' íŒŒí‹°ì…˜ ìˆ˜ ìë™ ê°ì§€: {} â†’ Consumer concurrency: {}",
                            topicName, partitionCount, partitionCount);

                    return partitionCount;
                }
            } catch (org.apache.kafka.common.errors.UnknownTopicOrPartitionException e) {
                log.warn("âš ï¸ í† í”½ '{}' ì´ ì•„ì§ ìƒì„±ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì¬ì‹œë„ {}/{}", topicName, retry + 1, maxRetries);
                try {
                    Thread.sleep(retryDelayMs);
                } catch (InterruptedException ie) {
                    Thread.currentThread().interrupt();
                    break;
                }
            } catch (Exception e) {
                log.warn("âš ï¸ í† í”½ íŒŒí‹°ì…˜ ìˆ˜ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ ë°œìƒ. ì¬ì‹œë„ {}/{}: {}", retry + 1, maxRetries, e.getMessage());
                try {
                    Thread.sleep(retryDelayMs);
                } catch (InterruptedException ie) {
                    Thread.currentThread().interrupt();
                    break;
                }
            }
        }

        log.warn("âš ï¸ ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜ ì´ˆê³¼. ê¸°ë³¸ê°’ 1 ì‚¬ìš©");
        return 1; // ê¸°ë³¸ê°’
    }
}
