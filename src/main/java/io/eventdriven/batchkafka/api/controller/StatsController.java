package io.eventdriven.batchkafka.api.controller;

import io.eventdriven.batchkafka.api.common.ApiResponse;
import io.eventdriven.batchkafka.domain.entity.CampaignStats;
import io.eventdriven.batchkafka.domain.entity.ParticipationHistory;
import io.eventdriven.batchkafka.domain.repository.CampaignStatsRepository;
import io.eventdriven.batchkafka.domain.repository.ParticipationHistoryRepository;
import lombok.RequiredArgsConstructor;
import lombok.extern.slf4j.Slf4j;
import org.springframework.format.annotation.DateTimeFormat;
import org.springframework.http.ResponseEntity;
import org.springframework.jdbc.core.JdbcTemplate;
import org.springframework.web.bind.annotation.*;

import java.time.Instant;
import java.time.LocalDate;
import java.time.ZoneId;
import java.util.HashMap;
import java.util.List;
import java.util.Map;
import java.util.stream.Collectors;

/**
 * ìº í˜ì¸ í†µê³„ ì¡°íšŒ API
 * - ì¼ìë³„ ì§‘ê³„ ë°ì´í„° ì¡°íšŒ
 */
@Slf4j
@RestController
@RequestMapping("/api/admin/stats")
@RequiredArgsConstructor
public class StatsController {

    private final CampaignStatsRepository statsRepository;
    private final ParticipationHistoryRepository participationHistoryRepository;
    private final JdbcTemplate jdbcTemplate;

    /**
     * ì›ë³¸ ë°ì´í„° ì§ì ‘ ì§‘ê³„ (ë°°ì¹˜ ì—†ì´ - ëŠë¦° API, ì„±ëŠ¥ ë¹„êµìš©)
     * GET /api/admin/stats/raw?date=2025-12-26
     */
    @GetMapping("/raw")
    public ResponseEntity<ApiResponse<?>> getRawStats(
            @RequestParam("date") @DateTimeFormat(iso = DateTimeFormat.ISO.DATE) LocalDate date
    ) {
        try {
            long startTime = System.currentTimeMillis();

            // ë°°ì¹˜ ì—†ì´ ì›ë³¸ í…Œì´ë¸”ì—ì„œ ì§ì ‘ ì§‘ê³„ (ëŠë¦¼!)
            String sql = """
                SELECT
                    c.id as campaign_id,
                    c.name as campaign_name,
                    COALESCE(SUM(CASE WHEN p.status = 'SUCCESS' THEN 1 ELSE 0 END), 0) as success_count,
                    COALESCE(SUM(CASE WHEN p.status = 'FAIL' THEN 1 ELSE 0 END), 0) as fail_count,
                    COALESCE(COUNT(p.id), 0) as total_count
                FROM campaign c
                LEFT JOIN participation_history p ON c.id = p.campaign_id AND DATE(p.created_at) = ?
                GROUP BY c.id, c.name
                HAVING total_count > 0
            """;

            List<Map<String, Object>> campaigns = jdbcTemplate.query(sql,
                (rs, rowNum) -> {
                    Map<String, Object> item = new HashMap<>();
                    item.put("campaignId", rs.getLong("campaign_id"));
                    item.put("campaignName", rs.getString("campaign_name"));
                    item.put("successCount", rs.getLong("success_count"));
                    item.put("failCount", rs.getLong("fail_count"));
                    item.put("totalCount", rs.getLong("total_count"));
                    long success = rs.getLong("success_count");
                    long total = rs.getLong("total_count");
                    item.put("successRate", total > 0 ?
                        String.format("%.2f%%", (success * 100.0 / total)) : "0.00%");
                    return item;
                },
                java.sql.Date.valueOf(date)
            );

            long endTime = System.currentTimeMillis();
            long duration = endTime - startTime;

            // ì „ì²´ ì§‘ê³„
            long totalSuccess = campaigns.stream()
                .mapToLong(c -> ((Number) c.get("successCount")).longValue()).sum();
            long totalFail = campaigns.stream()
                .mapToLong(c -> ((Number) c.get("failCount")).longValue()).sum();
            long totalCount = totalSuccess + totalFail;

            Map<String, Object> data = new HashMap<>();
            data.put("date", date.toString());
            data.put("method", "RAW_QUERY");
            data.put("queryTimeMs", duration);  // ì¿¼ë¦¬ ì‹¤í–‰ ì‹œê°„
            data.put("summary", Map.of(
                    "totalCampaigns", campaigns.size(),
                    "totalSuccess", totalSuccess,
                    "totalFail", totalFail,
                    "totalParticipation", totalCount,
                    "overallSuccessRate", totalCount > 0 ?
                            String.format("%.2f%%", (totalSuccess * 100.0 / totalCount)) : "0.00%"
            ));
            data.put("campaigns", campaigns);

            log.info("ğŸ“Š ì›ë³¸ ì§‘ê³„ ì™„ë£Œ - date: {}, queryTime: {}ms", date, duration);

            return ResponseEntity.ok(ApiResponse.success(data));

        } catch (Exception e) {
            log.error("ğŸš¨ ì›ë³¸ í†µê³„ ì¡°íšŒ ì‹¤íŒ¨ - date: {}", date, e);
            return ResponseEntity.internalServerError()
                    .body(ApiResponse.fail("í†µê³„ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."));
        }
    }

    /**
     * íŠ¹ì • ë‚ ì§œì˜ ì „ì²´ ìº í˜ì¸ í†µê³„ ì¡°íšŒ (ë°°ì¹˜ ì§‘ê³„ í›„ - ë¹ ë¥¸ API)
     * GET /api/admin/stats/daily?date=2025-12-26
     */
    @GetMapping("/daily")
    public ResponseEntity<ApiResponse<?>> getDailyStats(
            @RequestParam("date") @DateTimeFormat(iso = DateTimeFormat.ISO.DATE) LocalDate date
    ) {
        try {
            long startTime = System.currentTimeMillis();

            List<CampaignStats> stats = statsRepository.findByStatsDate(date);

            long endTime = System.currentTimeMillis();
            long duration = endTime - startTime;

            if (stats.isEmpty()) {
                Map<String, Object> emptyData = new HashMap<>();
                emptyData.put("date", date.toString());
                emptyData.put("method", "BATCH_AGGREGATED");
                emptyData.put("queryTimeMs", duration);
                emptyData.put("campaigns", List.of());
                return ResponseEntity.ok(
                        ApiResponse.success("í•´ë‹¹ ë‚ ì§œì˜ ì§‘ê³„ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ë°°ì¹˜ë¥¼ ë¨¼ì € ì‹¤í–‰í•´ì£¼ì„¸ìš”.", emptyData)
                );
            }

            // í†µê³„ ë°ì´í„°ë¥¼ DTOë¡œ ë³€í™˜
            List<Map<String, Object>> campaigns = stats.stream()
                    .map(stat -> {
                        Map<String, Object> item = new HashMap<>();
                        item.put("campaignId", stat.getCampaign().getId());
                        item.put("campaignName", stat.getCampaign().getName());
                        item.put("successCount", stat.getSuccessCount());
                        item.put("failCount", stat.getFailCount());
                        item.put("totalCount", stat.getSuccessCount() + stat.getFailCount());
                        item.put("successRate", calculateSuccessRate(stat));
                        item.put("statsDate", stat.getStatsDate());
                        return item;
                    })
                    .collect(Collectors.toList());

            // ì „ì²´ ì§‘ê³„
            long totalSuccess = stats.stream().mapToLong(CampaignStats::getSuccessCount).sum();
            long totalFail = stats.stream().mapToLong(CampaignStats::getFailCount).sum();
            long totalCount = totalSuccess + totalFail;

            Map<String, Object> data = new HashMap<>();
            data.put("date", date.toString());
            data.put("method", "BATCH_AGGREGATED");
            data.put("queryTimeMs", duration);  // ì¿¼ë¦¬ ì‹¤í–‰ ì‹œê°„
            data.put("summary", Map.of(
                    "totalCampaigns", stats.size(),
                    "totalSuccess", totalSuccess,
                    "totalFail", totalFail,
                    "totalParticipation", totalCount,
                    "overallSuccessRate", totalCount > 0 ?
                            String.format("%.2f%%", (totalSuccess * 100.0 / totalCount)) : "0.00%"
            ));
            data.put("campaigns", campaigns);

            log.info("ğŸ“Š ë°°ì¹˜ ì§‘ê³„ ì¡°íšŒ ì™„ë£Œ - date: {}, queryTime: {}ms", date, duration);

            return ResponseEntity.ok(ApiResponse.success(data));

        } catch (Exception e) {
            log.error("ğŸš¨ í†µê³„ ì¡°íšŒ ì‹¤íŒ¨ - date: {}", date, e);
            return ResponseEntity.internalServerError()
                    .body(ApiResponse.fail("í†µê³„ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."));
        }
    }

    /**
     * íŠ¹ì • ìº í˜ì¸ì˜ ì¼ìë³„ í†µê³„ ì¡°íšŒ
     * GET /api/admin/stats/campaign/{campaignId}?startDate=2025-12-01&endDate=2025-12-31
     */
    @GetMapping("/campaign/{campaignId}")
    public ResponseEntity<ApiResponse<?>> getCampaignStats(
            @PathVariable Long campaignId,
            @RequestParam(required = false) @DateTimeFormat(iso = DateTimeFormat.ISO.DATE) LocalDate startDate,
            @RequestParam(required = false) @DateTimeFormat(iso = DateTimeFormat.ISO.DATE) LocalDate endDate
    ) {
        try {
            // ê¸°ë³¸ê°’: ìµœê·¼ 7ì¼
            if (startDate == null) {
                startDate = LocalDate.now().minusDays(7);
            }
            if (endDate == null) {
                endDate = LocalDate.now();
            }

            // ë‚ ì§œ ë²”ìœ„ ê²€ì¦
            if (startDate.isAfter(endDate)) {
                return ResponseEntity.badRequest()
                        .body(ApiResponse.fail("ì‹œì‘ ë‚ ì§œëŠ” ì¢…ë£Œ ë‚ ì§œë³´ë‹¤ ì´ì „ì´ì–´ì•¼ í•©ë‹ˆë‹¤."));
            }

            List<CampaignStats> stats = statsRepository.findByCampaignIdAndStatsDateBetween(
                    campaignId, startDate, endDate);

            if (stats.isEmpty()) {
                Map<String, Object> emptyData = Map.of(
                        "campaignId", campaignId,
                        "startDate", startDate.toString(),
                        "endDate", endDate.toString(),
                        "dailyStats", List.of()
                );
                return ResponseEntity.ok(
                        ApiResponse.success("í•´ë‹¹ ê¸°ê°„ì˜ í†µê³„ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.", emptyData)
                );
            }

            // ì¼ìë³„ í†µê³„
            List<Map<String, Object>> dailyStats = stats.stream()
                    .<Map<String, Object>>map(stat -> Map.of(
                            "date", stat.getStatsDate().toString(),
                            "successCount", stat.getSuccessCount(),
                            "failCount", stat.getFailCount(),
                            "totalCount", stat.getSuccessCount() + stat.getFailCount(),
                            "successRate", calculateSuccessRate(stat)
                    ))
                    .collect(Collectors.toList());

            // ê¸°ê°„ ì§‘ê³„
            long totalSuccess = stats.stream().mapToLong(CampaignStats::getSuccessCount).sum();
            long totalFail = stats.stream().mapToLong(CampaignStats::getFailCount).sum();
            long totalCount = totalSuccess + totalFail;

            Map<String, Object> data = new HashMap<>();
            data.put("campaignId", campaignId);
            data.put("campaignName", stats.get(0).getCampaign().getName());
            data.put("startDate", startDate.toString());
            data.put("endDate", endDate.toString());
            data.put("summary", Map.of(
                    "totalSuccess", totalSuccess,
                    "totalFail", totalFail,
                    "totalParticipation", totalCount,
                    "averageSuccessRate", totalCount > 0 ?
                            String.format("%.2f%%", (totalSuccess * 100.0 / totalCount)) : "0.00%"
            ));
            data.put("dailyStats", dailyStats);

            return ResponseEntity.ok(ApiResponse.success(data));

        } catch (Exception e) {
            log.error("ğŸš¨ ìº í˜ì¸ í†µê³„ ì¡°íšŒ ì‹¤íŒ¨ - campaignId: {}", campaignId, e);
            return ResponseEntity.internalServerError()
                    .body(ApiResponse.fail("í†µê³„ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."));
        }
    }

    /**
     * ì„±ê³µë¥  ê³„ì‚°
     */
    private String calculateSuccessRate(CampaignStats stat) {
        long total = stat.getSuccessCount() + stat.getFailCount();
        if (total == 0) {
            return "0.00%";
        }
        double rate = (stat.getSuccessCount() * 100.0) / total;
        return String.format("%.2f%%", rate);
    }

    /**
     * ìˆœì„œ ìœ„ë°˜ ì¼€ì´ìŠ¤ë§Œ ì¶”ì¶œ (ê²€ì¦ìš©)
     * GET /api/admin/stats/order-violations/{campaignId}?limit=100
     */
    @GetMapping("/order-violations/{campaignId}")
    public ResponseEntity<ApiResponse<?>> getOrderViolations(
            @PathVariable Long campaignId,
            @RequestParam(defaultValue = "100") int limit) {
        try {
            long startTime = System.currentTimeMillis();

            // 1. ëª¨ë“  ë ˆì½”ë“œ ì¡°íšŒ
            List<ParticipationHistory> allRecords = participationHistoryRepository
                    .findByCampaignIdOrderByKafkaTimestampAsc(campaignId);

            if (allRecords.isEmpty()) {
                return ResponseEntity.ok(ApiResponse.success("ë°ì´í„° ì—†ìŒ", Map.of()));
            }

            // 2. Kafka offset ìˆœì„œë¡œ ì •ë ¬
            List<ParticipationHistory> arrivalOrder = allRecords.stream()
                    .filter(r -> r.getProcessingSequence() != null
                              && r.getKafkaPartition() != null
                              && r.getKafkaOffset() != null)
                    .sorted(java.util.Comparator.comparing(ParticipationHistory::getKafkaPartition)
                            .thenComparing(ParticipationHistory::getKafkaOffset))
                    .collect(Collectors.toList());

        log.info("### DEBUG: Top 5 arrivalOrder in getOrderViolations ###");
        for(int i=0; i < Math.min(5, arrivalOrder.size()); i++) {
            ParticipationHistory r = arrivalOrder.get(i);
            log.info("Item " + i + ": P=" + r.getKafkaPartition() + ", O=" + r.getKafkaOffset() + ", Seq=" + r.getProcessingSequence());
        }
        log.info("### END DEBUG ###");

            // 3. ìˆœì„œ ìœ„ë°˜ ì¼€ì´ìŠ¤ ì¶”ì¶œ
            List<Map<String, Object>> violations = new java.util.ArrayList<>();

            // ì „ì²´ êµ¬ê°„ ìŠ¤ìº”: ìœ„ë°˜ì€ ìµœëŒ€ limitê°œê¹Œì§€ë§Œ ìˆ˜ì§‘
            for (int i = 0; i < (arrivalOrder.size() - 1); i++) {
                if (violations.size() >= limit) break;

                ParticipationHistory current = arrivalOrder.get(i);
                ParticipationHistory next = arrivalOrder.get(i + 1);

                if (current.getProcessingSequence() > next.getProcessingSequence()) {
                    Map<String, Object> violation = new HashMap<>();
                    violation.put("index", i);
                    violation.put("current", Map.of(
                            "userId", current.getUserId(),
                            "timestamp", current.getKafkaTimestamp(),
                            "partition", current.getKafkaPartition(),
                            "offset", current.getKafkaOffset(),
                            "processingSeq", current.getProcessingSequence(),
                            "status", current.getStatus().toString()
                    ));
                    violation.put("next", Map.of(
                            "userId", next.getUserId(),
                            "timestamp", next.getKafkaTimestamp(),
                            "partition", next.getKafkaPartition(),
                            "offset", next.getKafkaOffset(),
                            "processingSeq", next.getProcessingSequence(),
                            "status", next.getStatus().toString()
                    ));
                    violation.put("explanation", String.format(
                            "offset P%d:%d(seq=%d)ê°€ P%d:%d(seq=%d)ë³´ë‹¤ ëŠ¦ê²Œ ì²˜ë¦¬ë¨",
                            current.getKafkaPartition(), current.getKafkaOffset(), current.getProcessingSequence(),
                            next.getKafkaPartition(), next.getKafkaOffset(), next.getProcessingSequence()
                    ));
                    violations.add(violation);
                }
            }

            long endTime = System.currentTimeMillis();

            Map<String, Object> data = new HashMap<>();
            data.put("campaignId", campaignId);
            data.put("totalRecords", arrivalOrder.size());
            data.put("violationsFound", violations.size());
            data.put("violations", violations);
            data.put("queryTimeMs", endTime - startTime);

            return ResponseEntity.ok(ApiResponse.success(data));

        } catch (Exception e) {
            log.error("ğŸš¨ ìˆœì„œ ìœ„ë°˜ ì¡°íšŒ ì‹¤íŒ¨ - campaignId: {}", campaignId, e);
            return ResponseEntity.internalServerError()
                    .body(ApiResponse.fail("ìˆœì„œ ìœ„ë°˜ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."));
        }
    }

    /**
     * ìˆœì„œ ë¶„ì„ API - Kafka offset ìˆœì„œ vs ì‹¤ì œ ì²˜ë¦¬ ìˆœì„œ ë¹„êµ
     * GET /api/admin/stats/order-analysis/{campaignId}
     *
     * === ì¸¡ì • ëª©ì  ===
     * íŒŒí‹°ì…˜ ìˆ˜ ì¦ê°€ì— ë”°ë¥¸ "Kafka offset ìˆœì„œ vs ì²˜ë¦¬ ìˆœì„œ" ì¼ì¹˜ë„ ì¸¡ì •
     * â†’ ì²˜ë¦¬ëŸ‰ ì¦ê°€ vs ìˆœì„œ ë³´ì¥ íŠ¸ë ˆì´ë“œì˜¤í”„ ë¶„ì„
     *
     * === Kafka offset ìˆœì„œ ì •ì˜ ===
     * KafkaëŠ” íŒŒí‹°ì…˜ ë‚´ì—ì„œ offset ìˆœì„œë¥¼ ë³´ì¥:
     * - 1ì°¨: kafkaPartition (íŒŒí‹°ì…˜ ë²ˆí˜¸)
     * - 2ì°¨: kafkaOffset (íŒŒí‹°ì…˜ ë‚´ ìˆœì„œ ë²ˆí˜¸, 0ë¶€í„° ì‹œì‘)
     *
     * íŒŒí‹°ì…˜ 1ê°œ: offset 0, 1, 2, 3, ... (ì™„ë²½í•œ ìˆœì„œ)
     * íŒŒí‹°ì…˜ 3ê°œ:
     *   - P0: 0, 1, 2, ... (íŒŒí‹°ì…˜ ë‚´ ìˆœì„œ)
     *   - P1: 0, 1, 2, ... (íŒŒí‹°ì…˜ ë‚´ ìˆœì„œ)
     *   - P2: 0, 1, 2, ... (íŒŒí‹°ì…˜ ë‚´ ìˆœì„œ)
     *   - íŒŒí‹°ì…˜ ê°„ ìˆœì„œëŠ” Consumer ìŠ¤ë ˆë“œ ê²½ìŸìœ¼ë¡œ ê²°ì •ë¨
     *
     * === ì²˜ë¦¬ ìˆœì„œ ===
     * processingSequence: Consumerê°€ ë©”ì‹œì§€ ì²˜ë¦¬ë¥¼ ì‹œì‘í•œ ì „ì—­ ìˆœì„œ ë²ˆí˜¸ (AtomicLong)
     * - ëª¨ë“  íŒŒí‹°ì…˜ í†µí‹€ì–´ì„œ 1, 2, 3, 4, ... ìˆœì°¨ ì¦ê°€
     *
     * === ì¸¡ì • ë°©ë²• ===
     * 1. ëª¨ë“  ë ˆì½”ë“œë¥¼ offset ìˆœì„œë¡œ ì •ë ¬ (partition â†’ offset)
     * 2. ì¸ì ‘í•œ ë ˆì½”ë“œ ìŒ ë¹„êµ:
     *    - offset ìˆœì„œìƒ ì•ì„  ë©”ì‹œì§€ê°€ ì²˜ë¦¬ ìˆœì„œìƒ ë’¤ë©´ â†’ ìˆœì„œ ë¶ˆì¼ì¹˜
     * 3. ìˆœì„œ ì •í™•ë„ = (ì¼ì¹˜ ìŒ / ì „ì²´ ìŒ) Ã— 100%
     *
     * === ê²°ê³¼ í•´ì„ ===
     * íŒŒí‹°ì…˜ 1ê°œ: 100% (offset ìˆœì„œ = ì²˜ë¦¬ ìˆœì„œ)
     * íŒŒí‹°ì…˜ 3ê°œ: ~33% (ê° íŒŒí‹°ì…˜ì€ ìˆœì„œ ìœ ì§€í•˜ì§€ë§Œ, íŒŒí‹°ì…˜ ê°„ ë’¤ì„ì„)
     * íŒŒí‹°ì…˜ 12ê°œ: ~8% (íŒŒí‹°ì…˜ ê°„ ì‹¬í•˜ê²Œ ë’¤ì„ì„)
     *
     * === ë¹„ì¦ˆë‹ˆìŠ¤ ì˜ë¯¸ ===
     * - íŒŒí‹°ì…˜ 1ê°œ: "ì„ ì°©ìˆœ"ì´ ì™„ë²½í•˜ê²Œ ë³´ì¥ë¨
     * - íŒŒí‹°ì…˜ 3ê°œ: íŒŒí‹°ì…˜ë³„ë¡œ "ì„ ì°©ìˆœ"ì´ì§€ë§Œ, ì „ì²´ì ìœ¼ë¡œëŠ” ì„ì„
     * - íŒŒí‹°ì…˜ 12ê°œ: "ì„ ì°©ìˆœ" ì˜ë¯¸ ì—†ìŒ, ì¬ê³ ë§Œ ì •í™•
     */
    @GetMapping("/order-analysis/{campaignId}")
    public ResponseEntity<ApiResponse<?>> analyzeProcessingOrder(@PathVariable Long campaignId) {
        try {
            long startTime = System.currentTimeMillis();

            // 1. Kafka ë©”íƒ€ë°ì´í„°ê°€ ìˆëŠ” ëª¨ë“  ì°¸ì—¬ ì´ë ¥ ì¡°íšŒ
            List<ParticipationHistory> allRecords = participationHistoryRepository
                    .findByCampaignIdOrderByKafkaTimestampAsc(campaignId);

            if (allRecords.isEmpty()) {
                Map<String, Object> emptyData = Map.of(
                        "campaignId", campaignId,
                        "message", "Kafka ë©”íƒ€ë°ì´í„°ê°€ ì—†ëŠ” ì°¸ì—¬ ì´ë ¥ì…ë‹ˆë‹¤. ìµœê·¼ í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¥¼ í™•ì¸í•˜ì„¸ìš”."
                );
                return ResponseEntity.ok(ApiResponse.success("ë°ì´í„° ì—†ìŒ", emptyData));
            }

            // 2. íŒŒí‹°ì…˜ë³„ë¡œ ë°ì´í„° ê·¸ë£¹í™” (íŒŒí‹°ì…˜ë³„ ìˆœì„œ ë¶„ì„ìš©)
            Map<Integer, List<ParticipationHistory>> partitionGroups = allRecords.stream()
                    .filter(r -> r.getKafkaPartition() != null && r.getKafkaOffset() != null)
                    .collect(Collectors.groupingBy(ParticipationHistory::getKafkaPartition));

            // 3-1. íŒŒí‹°ì…˜ë³„ ìˆœì„œ ë¶ˆì¼ì¹˜ ê³„ì‚° (ì°¸ê³ ìš©)
            Map<Integer, Integer> partitionMismatches = new HashMap<>();
            for (Map.Entry<Integer, List<ParticipationHistory>> entry : partitionGroups.entrySet()) {
                Integer partition = entry.getKey();
                List<ParticipationHistory> partitionRecords = entry.getValue();
                partitionRecords.sort(java.util.Comparator.comparing(ParticipationHistory::getKafkaOffset));

                int partitionMismatch = 0;
                for (int i = 0; i < partitionRecords.size() - 1; i++) {
                    ParticipationHistory current = partitionRecords.get(i);
                    ParticipationHistory next = partitionRecords.get(i + 1);

                    boolean orderMismatch;
                    if (current.getProcessingStartedAtNanos() != null && next.getProcessingStartedAtNanos() != null) {
                        orderMismatch = current.getProcessingStartedAtNanos() > next.getProcessingStartedAtNanos();
                    } else {
                        orderMismatch = current.getCreatedAt().isAfter(next.getCreatedAt());
                    }

                    if (orderMismatch) {
                        partitionMismatch++;
                    }
                }
                partitionMismatches.put(partition, partitionMismatch);
            }

            // 3-2. ì „ì—­ ìˆœì„œ ë¶ˆì¼ì¹˜ ê³„ì‚° (Kafka offset ìˆœì„œ vs ì²˜ë¦¬ ìˆœì„œ)

            // Kafka ìˆœì„œ ì •ì˜: partition â†’ offset
            // (KafkaëŠ” íŒŒí‹°ì…˜ ë‚´ offset ìˆœì„œë¥¼ ë³´ì¥í•˜ë¯€ë¡œ, ì´ê²ƒì´ ì§„ì§œ ë„ì°© ìˆœì„œ)
            List<ParticipationHistory> arrivalOrder = allRecords.stream()
                    .filter(r -> r.getProcessingSequence() != null
                              && r.getKafkaPartition() != null
                              && r.getKafkaOffset() != null)
                    .sorted(java.util.Comparator.comparing(ParticipationHistory::getKafkaPartition)
                            .thenComparing(ParticipationHistory::getKafkaOffset))
                    .collect(Collectors.toList());

            // ë©”ì¸ ì§€í‘œ: ì „ì²´ ë„ì°© ìˆœì„œ ê¸°ì¤€
            int totalOrderMismatches = 0;
            int totalComparisons = arrivalOrder.size() - 1;

            for (int i = 0; i < arrivalOrder.size() - 1; i++) {
                ParticipationHistory current = arrivalOrder.get(i);
                ParticipationHistory next = arrivalOrder.get(i + 1);

                // ë„ì°© ìˆœì„œìƒ ì•ì„  ë©”ì‹œì§€ê°€ ë‚˜ì¤‘ì— ì²˜ë¦¬ë˜ì—ˆìœ¼ë©´ ìˆœì„œ ìœ„ë°˜
                if (current.getProcessingSequence() > next.getProcessingSequence()) {
                    totalOrderMismatches++;
                }
            }

            double orderAccuracy = totalComparisons > 0
                    ? 100.0 * (totalComparisons - totalOrderMismatches) / totalComparisons
                    : 100.0;

            // 4. íŒŒí‹°ì…˜ë³„ ë©”ì‹œì§€ ë¶„í¬
            Map<Integer, Long> partitionDistribution = partitionGroups.entrySet().stream()
                    .collect(Collectors.toMap(
                            Map.Entry::getKey,
                            e -> (long) e.getValue().size()
                    ));

            // 5. ìƒ˜í”Œ ë°ì´í„° (ê° íŒŒí‹°ì…˜ì—ì„œ ì²˜ìŒ 10ê°œì”©, ìˆœì„œ ìœ„ë°˜ ì¼€ì´ìŠ¤ í¬í•¨)
            List<Map<String, Object>> samples = new java.util.ArrayList<>();
            for (Map.Entry<Integer, List<ParticipationHistory>> entry : partitionGroups.entrySet()) {
                Integer partition = entry.getKey();
                List<ParticipationHistory> partitionRecords = entry.getValue();

                // offset ìˆœì„œë¡œ ì •ë ¬
                partitionRecords.sort(java.util.Comparator.comparing(ParticipationHistory::getKafkaOffset));

                // ê° íŒŒí‹°ì…˜ì—ì„œ ì²˜ìŒ 10ê°œë§Œ
                for (int i = 0; i < Math.min(10, partitionRecords.size()); i++) {
                    ParticipationHistory r = partitionRecords.get(i);
                    Map<String, Object> sample = new HashMap<>();
                    sample.put("partition", r.getKafkaPartition());
                    sample.put("offset", r.getKafkaOffset());
                    sample.put("userId", r.getUserId());
                    sample.put("status", r.getStatus().toString());
                    sample.put("processingSequence", r.getProcessingSequence()); // ì²˜ë¦¬ ìˆœì„œ ë²ˆí˜¸
                    sample.put("kafkaTimestamp", r.getKafkaTimestamp() != null
                            ? Instant.ofEpochMilli(r.getKafkaTimestamp())
                                    .atZone(ZoneId.of("Asia/Seoul"))
                                    .toLocalDateTime()
                                    .toString()
                            : null);
                    sample.put("processedAt", r.getCreatedAt().toString());

                    // ë‹¤ìŒ ë ˆì½”ë“œì™€ ë¹„êµí•˜ì—¬ ìˆœì„œ ìœ„ë°˜ ì—¬ë¶€ í‘œì‹œ
                    if (i < partitionRecords.size() - 1) {
                        ParticipationHistory next = partitionRecords.get(i + 1);
                        // processingSequenceê°€ ìˆìœ¼ë©´ ê·¸ê±¸ë¡œ ë¹„êµ, ì—†ìœ¼ë©´ createdAtìœ¼ë¡œ ë¹„êµ
                        boolean orderViolation = false;
                        if (r.getProcessingSequence() != null && next.getProcessingSequence() != null) {
                            orderViolation = r.getProcessingSequence() > next.getProcessingSequence();
                        } else {
                            orderViolation = r.getCreatedAt().isAfter(next.getCreatedAt());
                        }
                        sample.put("orderViolation", orderViolation);
                    } else {
                        sample.put("orderViolation", false);
                    }

                    samples.add(sample);
                }
            }

            long endTime = System.currentTimeMillis();
            long duration = endTime - startTime;

            // 6. ì‘ë‹µ ë°ì´í„° êµ¬ì„±
            Map<String, Object> data = new HashMap<>();
            data.put("campaignId", campaignId);
            data.put("queryTimeMs", duration);

            // ë©”ì¸ ì§€í‘œ
            data.put("summary", Map.of(
                    "totalRecords", allRecords.size(),
                    "orderMismatches", totalOrderMismatches,
                    "orderAccuracy", String.format("%.2f%%", orderAccuracy),
                    "partitionCount", partitionGroups.size(),
                    "totalComparisons", totalComparisons
            ));

            data.put("partitionDistribution", partitionDistribution);
            data.put("partitionMismatches", partitionMismatches);
            data.put("samples", samples);

            // í•´ì„ ê°€ì´ë“œ
            data.put("interpretation", Map.of(
                    "orderAccuracy", "Kafka offset ìˆœì„œ ê¸°ì¤€ (partition â†’ offset)",
                    "guide", orderAccuracy >= 99.0 ? "ì™„ë²½í•œ ìˆœì„œ ë³´ì¥ (íŒŒí‹°ì…˜ ë‚´)" :
                             orderAccuracy >= 95.0 ? "ë†’ì€ ìˆœì„œ ë³´ì¥" :
                             orderAccuracy >= 85.0 ? "ì¤‘ê°„ ìˆœì„œ ë³´ì¥" :
                             "ë‚®ì€ ìˆœì„œ ë³´ì¥ (íŒŒí‹°ì…˜ ë§ìŒ)",
                    "note", partitionGroups.size() == 1
                            ? "íŒŒí‹°ì…˜ 1ê°œ: offset ìˆœì„œ = ì²˜ë¦¬ ìˆœì„œ (100% ê¸°ëŒ€)"
                            : "íŒŒí‹°ì…˜ " + partitionGroups.size() + "ê°œ: íŒŒí‹°ì…˜ ë‚´ì—ì„œë§Œ ìˆœì„œ ë³´ì¥, íŒŒí‹°ì…˜ ê°„ì€ ê²½ìŸ"
            ));

            log.info("ğŸ“Š ìˆœì„œ ë¶„ì„ ì™„ë£Œ - campaignId: {}, totalRecords: {}, partitions: {}, orderAccuracy: {:.2f}%, queryTime: {}ms",
                    campaignId, allRecords.size(), partitionGroups.size(), orderAccuracy, duration);

            return ResponseEntity.ok(ApiResponse.success(data));

        } catch (Exception e) {
            log.error("ğŸš¨ ìˆœì„œ ë¶„ì„ ì‹¤íŒ¨ - campaignId: {}", campaignId, e);
            return ResponseEntity.internalServerError()
                    .body(ApiResponse.fail("ìˆœì„œ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."));
        }
    }
}
