package io.eventdriven.batchkafka.api.controller;

import io.eventdriven.batchkafka.api.common.ApiResponse;
import io.eventdriven.batchkafka.domain.entity.CampaignStats;
import io.eventdriven.batchkafka.domain.entity.ParticipationHistory;
import io.eventdriven.batchkafka.domain.repository.CampaignStatsRepository;
import io.eventdriven.batchkafka.domain.repository.ParticipationHistoryRepository;
import lombok.RequiredArgsConstructor;
import lombok.extern.slf4j.Slf4j;
import org.springframework.format.annotation.DateTimeFormat;
import org.springframework.http.ResponseEntity;
import org.springframework.jdbc.core.JdbcTemplate;
import org.springframework.web.bind.annotation.*;

import java.time.Instant;
import java.time.LocalDate;
import java.time.ZoneId;
import java.util.HashMap;
import java.util.List;
import java.util.Map;
import java.util.stream.Collectors;

/**
 * ìº í˜ì¸ í†µê³„ ì¡°íšŒ API
 * - ì¼ìë³„ ì§‘ê³„ ë°ì´í„° ì¡°íšŒ
 */
@Slf4j
@RestController
@RequestMapping("/api/admin/stats")
@RequiredArgsConstructor
public class StatsController {

    private final CampaignStatsRepository statsRepository;
    private final ParticipationHistoryRepository participationHistoryRepository;
    private final JdbcTemplate jdbcTemplate;

    /**
     * ì›ë³¸ ë°ì´í„° ì§ì ‘ ì§‘ê³„ (ë°°ì¹˜ ì—†ì´ - ëŠë¦° API, ì„±ëŠ¥ ë¹„êµìš©)
     * GET /api/admin/stats/raw?date=2025-12-26
     */
    @GetMapping("/raw")
    public ResponseEntity<ApiResponse<?>> getRawStats(
            @RequestParam("date") @DateTimeFormat(iso = DateTimeFormat.ISO.DATE) LocalDate date
    ) {
        try {
            long startTime = System.currentTimeMillis();

            // ë°°ì¹˜ ì—†ì´ ì›ë³¸ í…Œì´ë¸”ì—ì„œ ì§ì ‘ ì§‘ê³„ (ëŠë¦¼!)
            String sql = """
                SELECT
                    c.id as campaign_id,
                    c.name as campaign_name,
                    COALESCE(SUM(CASE WHEN p.status = 'SUCCESS' THEN 1 ELSE 0 END), 0) as success_count,
                    COALESCE(SUM(CASE WHEN p.status = 'FAIL' THEN 1 ELSE 0 END), 0) as fail_count,
                    COALESCE(COUNT(p.id), 0) as total_count
                FROM campaign c
                LEFT JOIN participation_history p ON c.id = p.campaign_id AND DATE(p.created_at) = ?
                GROUP BY c.id, c.name
                HAVING total_count > 0
            """;

            List<Map<String, Object>> campaigns = jdbcTemplate.query(sql,
                (rs, rowNum) -> {
                    Map<String, Object> item = new HashMap<>();
                    item.put("campaignId", rs.getLong("campaign_id"));
                    item.put("campaignName", rs.getString("campaign_name"));
                    item.put("successCount", rs.getLong("success_count"));
                    item.put("failCount", rs.getLong("fail_count"));
                    item.put("totalCount", rs.getLong("total_count"));
                    long success = rs.getLong("success_count");
                    long total = rs.getLong("total_count");
                    item.put("successRate", total > 0 ?
                        String.format("%.2f%%", (success * 100.0 / total)) : "0.00%");
                    return item;
                },
                java.sql.Date.valueOf(date)
            );

            long endTime = System.currentTimeMillis();
            long duration = endTime - startTime;

            // ì „ì²´ ì§‘ê³„
            long totalSuccess = campaigns.stream()
                .mapToLong(c -> ((Number) c.get("successCount")).longValue()).sum();
            long totalFail = campaigns.stream()
                .mapToLong(c -> ((Number) c.get("failCount")).longValue()).sum();
            long totalCount = totalSuccess + totalFail;

            Map<String, Object> data = new HashMap<>();
            data.put("date", date.toString());
            data.put("method", "RAW_QUERY");
            data.put("queryTimeMs", duration);  // ì¿¼ë¦¬ ì‹¤í–‰ ì‹œê°„
            data.put("summary", Map.of(
                    "totalCampaigns", campaigns.size(),
                    "totalSuccess", totalSuccess,
                    "totalFail", totalFail,
                    "totalParticipation", totalCount,
                    "overallSuccessRate", totalCount > 0 ?
                            String.format("%.2f%%", (totalSuccess * 100.0 / totalCount)) : "0.00%"
            ));
            data.put("campaigns", campaigns);

            log.info("ğŸ“Š ì›ë³¸ ì§‘ê³„ ì™„ë£Œ - date: {}, queryTime: {}ms", date, duration);

            return ResponseEntity.ok(ApiResponse.success(data));

        } catch (Exception e) {
            log.error("ğŸš¨ ì›ë³¸ í†µê³„ ì¡°íšŒ ì‹¤íŒ¨ - date: {}", date, e);
            return ResponseEntity.internalServerError()
                    .body(ApiResponse.fail("í†µê³„ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."));
        }
    }

    /**
     * íŠ¹ì • ë‚ ì§œì˜ ì „ì²´ ìº í˜ì¸ í†µê³„ ì¡°íšŒ (ë°°ì¹˜ ì§‘ê³„ í›„ - ë¹ ë¥¸ API)
     * GET /api/admin/stats/daily?date=2025-12-26
     */
    @GetMapping("/daily")
    public ResponseEntity<ApiResponse<?>> getDailyStats(
            @RequestParam("date") @DateTimeFormat(iso = DateTimeFormat.ISO.DATE) LocalDate date
    ) {
        try {
            long startTime = System.currentTimeMillis();

            List<CampaignStats> stats = statsRepository.findByStatsDate(date);

            long endTime = System.currentTimeMillis();
            long duration = endTime - startTime;

            if (stats.isEmpty()) {
                Map<String, Object> emptyData = new HashMap<>();
                emptyData.put("date", date.toString());
                emptyData.put("method", "BATCH_AGGREGATED");
                emptyData.put("queryTimeMs", duration);
                emptyData.put("campaigns", List.of());
                return ResponseEntity.ok(
                        ApiResponse.success("í•´ë‹¹ ë‚ ì§œì˜ ì§‘ê³„ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ë°°ì¹˜ë¥¼ ë¨¼ì € ì‹¤í–‰í•´ì£¼ì„¸ìš”.", emptyData)
                );
            }

            // í†µê³„ ë°ì´í„°ë¥¼ DTOë¡œ ë³€í™˜
            List<Map<String, Object>> campaigns = stats.stream()
                    .map(stat -> {
                        Map<String, Object> item = new HashMap<>();
                        item.put("campaignId", stat.getCampaign().getId());
                        item.put("campaignName", stat.getCampaign().getName());
                        item.put("successCount", stat.getSuccessCount());
                        item.put("failCount", stat.getFailCount());
                        item.put("totalCount", stat.getSuccessCount() + stat.getFailCount());
                        item.put("successRate", calculateSuccessRate(stat));
                        item.put("statsDate", stat.getStatsDate());
                        return item;
                    })
                    .collect(Collectors.toList());

            // ì „ì²´ ì§‘ê³„
            long totalSuccess = stats.stream().mapToLong(CampaignStats::getSuccessCount).sum();
            long totalFail = stats.stream().mapToLong(CampaignStats::getFailCount).sum();
            long totalCount = totalSuccess + totalFail;

            Map<String, Object> data = new HashMap<>();
            data.put("date", date.toString());
            data.put("method", "BATCH_AGGREGATED");
            data.put("queryTimeMs", duration);  // ì¿¼ë¦¬ ì‹¤í–‰ ì‹œê°„
            data.put("summary", Map.of(
                    "totalCampaigns", stats.size(),
                    "totalSuccess", totalSuccess,
                    "totalFail", totalFail,
                    "totalParticipation", totalCount,
                    "overallSuccessRate", totalCount > 0 ?
                            String.format("%.2f%%", (totalSuccess * 100.0 / totalCount)) : "0.00%"
            ));
            data.put("campaigns", campaigns);

            log.info("ğŸ“Š ë°°ì¹˜ ì§‘ê³„ ì¡°íšŒ ì™„ë£Œ - date: {}, queryTime: {}ms", date, duration);

            return ResponseEntity.ok(ApiResponse.success(data));

        } catch (Exception e) {
            log.error("ğŸš¨ í†µê³„ ì¡°íšŒ ì‹¤íŒ¨ - date: {}", date, e);
            return ResponseEntity.internalServerError()
                    .body(ApiResponse.fail("í†µê³„ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."));
        }
    }

    /**
     * íŠ¹ì • ìº í˜ì¸ì˜ ì¼ìë³„ í†µê³„ ì¡°íšŒ
     * GET /api/admin/stats/campaign/{campaignId}?startDate=2025-12-01&endDate=2025-12-31
     */
    @GetMapping("/campaign/{campaignId}")
    public ResponseEntity<ApiResponse<?>> getCampaignStats(
            @PathVariable Long campaignId,
            @RequestParam(required = false) @DateTimeFormat(iso = DateTimeFormat.ISO.DATE) LocalDate startDate,
            @RequestParam(required = false) @DateTimeFormat(iso = DateTimeFormat.ISO.DATE) LocalDate endDate
    ) {
        try {
            // ê¸°ë³¸ê°’: ìµœê·¼ 7ì¼
            if (startDate == null) {
                startDate = LocalDate.now().minusDays(7);
            }
            if (endDate == null) {
                endDate = LocalDate.now();
            }

            // ë‚ ì§œ ë²”ìœ„ ê²€ì¦
            if (startDate.isAfter(endDate)) {
                return ResponseEntity.badRequest()
                        .body(ApiResponse.fail("ì‹œì‘ ë‚ ì§œëŠ” ì¢…ë£Œ ë‚ ì§œë³´ë‹¤ ì´ì „ì´ì–´ì•¼ í•©ë‹ˆë‹¤."));
            }

            List<CampaignStats> stats = statsRepository.findByCampaignIdAndStatsDateBetween(
                    campaignId, startDate, endDate);

            if (stats.isEmpty()) {
                Map<String, Object> emptyData = Map.of(
                        "campaignId", campaignId,
                        "startDate", startDate.toString(),
                        "endDate", endDate.toString(),
                        "dailyStats", List.of()
                );
                return ResponseEntity.ok(
                        ApiResponse.success("í•´ë‹¹ ê¸°ê°„ì˜ í†µê³„ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.", emptyData)
                );
            }

            // ì¼ìë³„ í†µê³„
            List<Map<String, Object>> dailyStats = stats.stream()
                    .<Map<String, Object>>map(stat -> Map.of(
                            "date", stat.getStatsDate().toString(),
                            "successCount", stat.getSuccessCount(),
                            "failCount", stat.getFailCount(),
                            "totalCount", stat.getSuccessCount() + stat.getFailCount(),
                            "successRate", calculateSuccessRate(stat)
                    ))
                    .collect(Collectors.toList());

            // ê¸°ê°„ ì§‘ê³„
            long totalSuccess = stats.stream().mapToLong(CampaignStats::getSuccessCount).sum();
            long totalFail = stats.stream().mapToLong(CampaignStats::getFailCount).sum();
            long totalCount = totalSuccess + totalFail;

            Map<String, Object> data = new HashMap<>();
            data.put("campaignId", campaignId);
            data.put("campaignName", stats.get(0).getCampaign().getName());
            data.put("startDate", startDate.toString());
            data.put("endDate", endDate.toString());
            data.put("summary", Map.of(
                    "totalSuccess", totalSuccess,
                    "totalFail", totalFail,
                    "totalParticipation", totalCount,
                    "averageSuccessRate", totalCount > 0 ?
                            String.format("%.2f%%", (totalSuccess * 100.0 / totalCount)) : "0.00%"
            ));
            data.put("dailyStats", dailyStats);

            return ResponseEntity.ok(ApiResponse.success(data));

        } catch (Exception e) {
            log.error("ğŸš¨ ìº í˜ì¸ í†µê³„ ì¡°íšŒ ì‹¤íŒ¨ - campaignId: {}", campaignId, e);
            return ResponseEntity.internalServerError()
                    .body(ApiResponse.fail("í†µê³„ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."));
        }
    }

    /**
     * ì„±ê³µë¥  ê³„ì‚°
     */
    private String calculateSuccessRate(CampaignStats stat) {
        long total = stat.getSuccessCount() + stat.getFailCount();
        if (total == 0) {
            return "0.00%";
        }
        double rate = (stat.getSuccessCount() * 100.0) / total;
        return String.format("%.2f%%", rate);
    }

    /**
     * ìˆœì„œ ìœ„ë°˜ ì¼€ì´ìŠ¤ë§Œ ì¶”ì¶œ (ê²€ì¦ìš©)
     * GET /api/admin/stats/order-violations/{campaignId}?limit=100
     */
    @GetMapping("/order-violations/{campaignId}")
    public ResponseEntity<ApiResponse<?>> getOrderViolations(
            @PathVariable Long campaignId,
            @RequestParam(defaultValue = "100") int limit) {
        try {
            long startTime = System.currentTimeMillis();

            // 1. ëª¨ë“  ë ˆì½”ë“œ ì¡°íšŒ
            List<ParticipationHistory> allRecords = participationHistoryRepository
                    .findByCampaignIdOrderByKafkaTimestampAsc(campaignId);

            if (allRecords.isEmpty()) {
                return ResponseEntity.ok(ApiResponse.success("ë°ì´í„° ì—†ìŒ", Map.of()));
            }

            // 2. Kafka timestamp ìˆœì„œë¡œ ì •ë ¬ (ì „ì—­ ë„ì°© ìˆœì„œ)
            // íŒŒí‹°ì…˜ ë²ˆí˜¸+ì˜¤í”„ì…‹ì´ ì•„ë‹Œ íƒ€ì„ìŠ¤íƒ¬í”„ë¡œ ì •ë ¬í•´ì•¼ ì§„ì •í•œ ì „ì—­ ìˆœì„œ
            List<ParticipationHistory> arrivalOrder = allRecords.stream()
                    .filter(r -> r.getProcessingSequence() != null
                              && r.getKafkaPartition() != null
                              && r.getKafkaOffset() != null
                              && r.getKafkaTimestamp() != null)
                    .sorted(java.util.Comparator.comparing(ParticipationHistory::getKafkaTimestamp)
                            .thenComparing(ParticipationHistory::getKafkaPartition)
                            .thenComparing(ParticipationHistory::getKafkaOffset))
                    .collect(Collectors.toList());

        log.info("### DEBUG: Top 5 arrivalOrder in getOrderViolations ###");
        for(int i=0; i < Math.min(5, arrivalOrder.size()); i++) {
            ParticipationHistory r = arrivalOrder.get(i);
            log.info("Item " + i + ": P=" + r.getKafkaPartition() + ", O=" + r.getKafkaOffset() + ", Seq=" + r.getProcessingSequence());
        }
        log.info("### END DEBUG ###");

            // 3. ì „ì²´ ì—­ì „ ìŒ ê³„ì‚° (Inversion Count)
            long[] processingSequences = arrivalOrder.stream()
                    .mapToLong(ParticipationHistory::getProcessingSequence)
                    .toArray();

            long inversionCount = countInversions(processingSequences);
            long n = processingSequences.length;
            long totalPairs = n * (n - 1) / 2;

            // 4. ìƒ˜í”Œ ì—­ì „ ì¼€ì´ìŠ¤ ì¶”ì¶œ (ìŠ¬ë¼ì´ë”© ìœˆë„ìš° ë°©ì‹)
            // - ê° ìœ„ì¹˜ì—ì„œ ì•ë’¤ ì¼ì • ë²”ìœ„ ë‚´ì—ì„œ ì—­ì „ ì¼€ì´ìŠ¤ ì°¾ê¸°
            List<Map<String, Object>> violations = new java.util.ArrayList<>();
            int windowSize = Math.min(100, arrivalOrder.size() / 10 + 1);  // ìœˆë„ìš° í¬ê¸°

            for (int i = 0; i < arrivalOrder.size() && violations.size() < limit; i++) {
                ParticipationHistory current = arrivalOrder.get(i);

                // í˜„ì¬ ìœ„ì¹˜ì—ì„œ ìœˆë„ìš° ë²”ìœ„ ë‚´ì—ì„œ ì—­ì „ ì¼€ì´ìŠ¤ ì°¾ê¸°
                int searchEnd = Math.min(i + windowSize, arrivalOrder.size());
                for (int j = i + 1; j < searchEnd && violations.size() < limit; j++) {
                    ParticipationHistory next = arrivalOrder.get(j);

                    // ì—­ì „ ë°œìƒ: ë¨¼ì € ë„ì°©(i)í–ˆëŠ”ë° ë‚˜ì¤‘ì— ì²˜ë¦¬ë¨(seqê°€ ë” í¼)
                    if (current.getProcessingSequence() > next.getProcessingSequence()) {
                        long timeDiff = Math.abs(next.getKafkaTimestamp() - current.getKafkaTimestamp());
                        Map<String, Object> violation = new HashMap<>();
                        violation.put("index", i);
                        violation.put("timeDiffMs", timeDiff);
                        violation.put("current", Map.of(
                                "userId", current.getUserId(),
                                "timestamp", current.getKafkaTimestamp(),
                                "partition", current.getKafkaPartition(),
                                "offset", current.getKafkaOffset(),
                                "processingSeq", current.getProcessingSequence(),
                                "status", current.getStatus().toString()
                        ));
                        violation.put("next", Map.of(
                                "userId", next.getUserId(),
                                "timestamp", next.getKafkaTimestamp(),
                                "partition", next.getKafkaPartition(),
                                "offset", next.getKafkaOffset(),
                                "processingSeq", next.getProcessingSequence(),
                                "status", next.getStatus().toString()
                        ));
                        violation.put("explanation", String.format(
                                "ts %d â†’ %d (diff=%dms): P%d:%d(seq=%d)ê°€ P%d:%d(seq=%d)ë³´ë‹¤ ëŠ¦ê²Œ ì²˜ë¦¬ë¨",
                                current.getKafkaTimestamp(), next.getKafkaTimestamp(), timeDiff,
                                current.getKafkaPartition(), current.getKafkaOffset(), current.getProcessingSequence(),
                                next.getKafkaPartition(), next.getKafkaOffset(), next.getProcessingSequence()
                        ));
                        violations.add(violation);
                        break;  // í˜„ì¬ ìœ„ì¹˜ì—ì„œ í•˜ë‚˜ ì°¾ìœ¼ë©´ ë‹¤ìŒìœ¼ë¡œ
                    }
                }
            }

            long endTime = System.currentTimeMillis();

            double orderAccuracy = totalPairs > 0
                    ? 100.0 * (totalPairs - inversionCount) / totalPairs
                    : 100.0;

            Map<String, Object> data = new HashMap<>();
            data.put("campaignId", campaignId);
            data.put("totalRecords", arrivalOrder.size());
            data.put("inversionCount", inversionCount);
            data.put("totalPairs", totalPairs);
            data.put("orderAccuracy", String.format("%.2f%%", orderAccuracy));
            data.put("sampleViolations", violations.size());
            data.put("violations", violations);
            data.put("queryTimeMs", endTime - startTime);

            return ResponseEntity.ok(ApiResponse.success(data));

        } catch (Exception e) {
            log.error("ğŸš¨ ìˆœì„œ ìœ„ë°˜ ì¡°íšŒ ì‹¤íŒ¨ - campaignId: {}", campaignId, e);
            return ResponseEntity.internalServerError()
                    .body(ApiResponse.fail("ìˆœì„œ ìœ„ë°˜ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."));
        }
    }

    /**
     * ìˆœì„œ ë¶„ì„ API - Kafka íƒ€ì„ìŠ¤íƒ¬í”„ ìˆœì„œ vs ì‹¤ì œ ì²˜ë¦¬ ìˆœì„œ ë¹„êµ
     * GET /api/admin/stats/order-analysis/{campaignId}
     *
     * === ì¸¡ì • ëª©ì  ===
     * íŒŒí‹°ì…˜ ìˆ˜ ì¦ê°€ì— ë”°ë¥¸ "ì „ì—­ ë„ì°© ìˆœì„œ vs ì²˜ë¦¬ ìˆœì„œ" ì¼ì¹˜ë„ ì¸¡ì •
     * â†’ ì²˜ë¦¬ëŸ‰ ì¦ê°€ vs ìˆœì„œ ë³´ì¥ íŠ¸ë ˆì´ë“œì˜¤í”„ ë¶„ì„
     *
     * === ì „ì—­ ë„ì°© ìˆœì„œ ì •ì˜ ===
     * Kafka íƒ€ì„ìŠ¤íƒ¬í”„(Producer CreateTime ë˜ëŠ” LogAppendTime)ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬
     * - íŒŒí‹°ì…˜+ì˜¤í”„ì…‹ì€ íŒŒí‹°ì…˜ ë‚´ ìˆœì„œì¼ ë¿, ì „ì—­ ìˆœì„œê°€ ì•„ë‹˜
     * - íƒ€ì„ìŠ¤íƒ¬í”„ê°€ ì‹¤ì œë¡œ ë©”ì‹œì§€ê°€ ë¸Œë¡œì»¤ì— ê¸°ë¡ëœ ì‹œê°„ì„ ë‚˜íƒ€ëƒ„
     *
     * === ì²˜ë¦¬ ìˆœì„œ ===
     * processingSequence: Consumerê°€ ë©”ì‹œì§€ ì²˜ë¦¬ë¥¼ ì‹œì‘í•œ ì „ì—­ ìˆœì„œ ë²ˆí˜¸ (AtomicLong)
     * - ëª¨ë“  íŒŒí‹°ì…˜ í†µí‹€ì–´ì„œ 1, 2, 3, 4, ... ìˆœì°¨ ì¦ê°€
     *
     * === ì¸¡ì • ë°©ë²• ===
     * 1. ëª¨ë“  ë ˆì½”ë“œë¥¼ Kafka íƒ€ì„ìŠ¤íƒ¬í”„ ìˆœì„œë¡œ ì •ë ¬ (ì „ì—­ ë„ì°© ìˆœì„œ)
     * 2. ì¸ì ‘í•œ ë ˆì½”ë“œ ìŒ ë¹„êµ:
     *    - íƒ€ì„ìŠ¤íƒ¬í”„ ìˆœì„œìƒ ì•ì„  ë©”ì‹œì§€ê°€ ì²˜ë¦¬ ìˆœì„œìƒ ë’¤ë©´ â†’ ìˆœì„œ ë¶ˆì¼ì¹˜
     * 3. ìˆœì„œ ì •í™•ë„ = (ì¼ì¹˜ ìŒ / ì „ì²´ ìŒ) Ã— 100%
     *
     * === ê²°ê³¼ í•´ì„ ===
     * ìˆœì„œ ì •í™•ë„ê°€ ë†’ì„ìˆ˜ë¡ "ë¨¼ì € ë„ì°©í•œ ìš”ì²­ì´ ë¨¼ì € ì²˜ë¦¬ë¨"
     * íŒŒí‹°ì…˜ ìˆ˜ê°€ ëŠ˜ì–´ë‚˜ë©´ ë³‘ë ¬ ì²˜ë¦¬ë¡œ ì¸í•´ ìˆœì„œ ì •í™•ë„ê°€ ë‚®ì•„ì§ˆ ìˆ˜ ìˆìŒ
     *
     * === ë¹„ì¦ˆë‹ˆìŠ¤ ì˜ë¯¸ ===
     * - ë†’ì€ ì •í™•ë„: "ì„ ì°©ìˆœ"ì´ ì˜ ë³´ì¥ë¨
     * - ë‚®ì€ ì •í™•ë„: ë³‘ë ¬ ì²˜ë¦¬ë¡œ ì¸í•´ ì²˜ë¦¬ ìˆœì„œê°€ ë„ì°© ìˆœì„œì™€ ë‹¤ë¦„
     */
    @GetMapping("/order-analysis/{campaignId}")
    public ResponseEntity<ApiResponse<?>> analyzeProcessingOrder(@PathVariable Long campaignId) {
        try {
            long startTime = System.currentTimeMillis();

            // 1. Kafka ë©”íƒ€ë°ì´í„°ê°€ ìˆëŠ” ëª¨ë“  ì°¸ì—¬ ì´ë ¥ ì¡°íšŒ
            List<ParticipationHistory> allRecords = participationHistoryRepository
                    .findByCampaignIdOrderByKafkaTimestampAsc(campaignId);

            if (allRecords.isEmpty()) {
                Map<String, Object> emptyData = Map.of(
                        "campaignId", campaignId,
                        "message", "Kafka ë©”íƒ€ë°ì´í„°ê°€ ì—†ëŠ” ì°¸ì—¬ ì´ë ¥ì…ë‹ˆë‹¤. ìµœê·¼ í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¥¼ í™•ì¸í•˜ì„¸ìš”."
                );
                return ResponseEntity.ok(ApiResponse.success("ë°ì´í„° ì—†ìŒ", emptyData));
            }

            // 2. íŒŒí‹°ì…˜ë³„ë¡œ ë°ì´í„° ê·¸ë£¹í™” (íŒŒí‹°ì…˜ë³„ ìˆœì„œ ë¶„ì„ìš©)
            Map<Integer, List<ParticipationHistory>> partitionGroups = allRecords.stream()
                    .filter(r -> r.getKafkaPartition() != null && r.getKafkaOffset() != null)
                    .collect(Collectors.groupingBy(ParticipationHistory::getKafkaPartition));

            // 3-1. íŒŒí‹°ì…˜ë³„ ìˆœì„œ ë¶ˆì¼ì¹˜ ê³„ì‚° (ì°¸ê³ ìš©)
            Map<Integer, Integer> partitionMismatches = new HashMap<>();
            for (Map.Entry<Integer, List<ParticipationHistory>> entry : partitionGroups.entrySet()) {
                Integer partition = entry.getKey();
                List<ParticipationHistory> partitionRecords = entry.getValue();
                partitionRecords.sort(java.util.Comparator.comparing(ParticipationHistory::getKafkaOffset));

                int partitionMismatch = 0;
                for (int i = 0; i < partitionRecords.size() - 1; i++) {
                    ParticipationHistory current = partitionRecords.get(i);
                    ParticipationHistory next = partitionRecords.get(i + 1);

                    boolean orderMismatch;
                    if (current.getProcessingStartedAtNanos() != null && next.getProcessingStartedAtNanos() != null) {
                        orderMismatch = current.getProcessingStartedAtNanos() > next.getProcessingStartedAtNanos();
                    } else {
                        orderMismatch = current.getCreatedAt().isAfter(next.getCreatedAt());
                    }

                    if (orderMismatch) {
                        partitionMismatch++;
                    }
                }
                partitionMismatches.put(partition, partitionMismatch);
            }

            // 3-2. ì „ì—­ ìˆœì„œ ë¶ˆì¼ì¹˜ ê³„ì‚° (Kafka íƒ€ì„ìŠ¤íƒ¬í”„ ìˆœì„œ vs ì²˜ë¦¬ ìˆœì„œ)

            // ì „ì—­ ë„ì°© ìˆœì„œ = Kafka íƒ€ì„ìŠ¤íƒ¬í”„ ê¸°ì¤€
            // (íŒŒí‹°ì…˜+ì˜¤í”„ì…‹ì€ íŒŒí‹°ì…˜ ë‚´ ìˆœì„œì¼ ë¿, ì „ì—­ ìˆœì„œê°€ ì•„ë‹˜)
            List<ParticipationHistory> arrivalOrder = allRecords.stream()
                    .filter(r -> r.getProcessingSequence() != null
                              && r.getKafkaPartition() != null
                              && r.getKafkaOffset() != null
                              && r.getKafkaTimestamp() != null)
                    .sorted(java.util.Comparator.comparing(ParticipationHistory::getKafkaTimestamp)
                            .thenComparing(ParticipationHistory::getKafkaPartition)
                            .thenComparing(ParticipationHistory::getKafkaOffset))
                    .collect(Collectors.toList());

            // ë©”ì¸ ì§€í‘œ: ì „ì—­ ìˆœì„œ ì—­ì „ ìŒ ê³„ì‚° (Inversion Count)
            // - íƒ€ì„ìŠ¤íƒ¬í”„ ìˆœìœ¼ë¡œ ì •ë ¬ëœ processingSequenceì—ì„œ ì—­ì „ ìŒ ìˆ˜ ê³„ì‚°
            // - ì—­ì „ = ë¨¼ì € ë„ì°©í•œ ë©”ì‹œì§€ê°€ ë‚˜ì¤‘ì— ì²˜ë¦¬ëœ ê²½ìš°
            // - O(n log n) Merge Sort ê¸°ë°˜ ì•Œê³ ë¦¬ì¦˜ ì‚¬ìš©

            long[] processingSequences = arrivalOrder.stream()
                    .mapToLong(ParticipationHistory::getProcessingSequence)
                    .toArray();

            long inversionCount = countInversions(processingSequences);
            long n = processingSequences.length;
            long totalPairs = n * (n - 1) / 2;  // ì „ì²´ ë¹„êµ ê°€ëŠ¥í•œ ìŒ ìˆ˜

            double orderAccuracy = totalPairs > 0
                    ? 100.0 * (totalPairs - inversionCount) / totalPairs
                    : 100.0;

            // 4. íŒŒí‹°ì…˜ë³„ ë©”ì‹œì§€ ë¶„í¬
            Map<Integer, Long> partitionDistribution = partitionGroups.entrySet().stream()
                    .collect(Collectors.toMap(
                            Map.Entry::getKey,
                            e -> (long) e.getValue().size()
                    ));

            // 5. ìƒ˜í”Œ ë°ì´í„° (ê° íŒŒí‹°ì…˜ì—ì„œ ì²˜ìŒ 10ê°œì”©, ìˆœì„œ ìœ„ë°˜ ì¼€ì´ìŠ¤ í¬í•¨)
            List<Map<String, Object>> samples = new java.util.ArrayList<>();
            for (Map.Entry<Integer, List<ParticipationHistory>> entry : partitionGroups.entrySet()) {
                Integer partition = entry.getKey();
                List<ParticipationHistory> partitionRecords = entry.getValue();

                // offset ìˆœì„œë¡œ ì •ë ¬
                partitionRecords.sort(java.util.Comparator.comparing(ParticipationHistory::getKafkaOffset));

                // ê° íŒŒí‹°ì…˜ì—ì„œ ì²˜ìŒ 10ê°œë§Œ
                for (int i = 0; i < Math.min(10, partitionRecords.size()); i++) {
                    ParticipationHistory r = partitionRecords.get(i);
                    Map<String, Object> sample = new HashMap<>();
                    sample.put("partition", r.getKafkaPartition());
                    sample.put("offset", r.getKafkaOffset());
                    sample.put("userId", r.getUserId());
                    sample.put("status", r.getStatus().toString());
                    sample.put("processingSequence", r.getProcessingSequence()); // ì²˜ë¦¬ ìˆœì„œ ë²ˆí˜¸
                    sample.put("kafkaTimestamp", r.getKafkaTimestamp() != null
                            ? Instant.ofEpochMilli(r.getKafkaTimestamp())
                                    .atZone(ZoneId.of("Asia/Seoul"))
                                    .toLocalDateTime()
                                    .toString()
                            : null);
                    sample.put("processedAt", r.getCreatedAt().toString());

                    // ë‹¤ìŒ ë ˆì½”ë“œì™€ ë¹„êµí•˜ì—¬ ìˆœì„œ ìœ„ë°˜ ì—¬ë¶€ í‘œì‹œ
                    if (i < partitionRecords.size() - 1) {
                        ParticipationHistory next = partitionRecords.get(i + 1);
                        // processingSequenceê°€ ìˆìœ¼ë©´ ê·¸ê±¸ë¡œ ë¹„êµ, ì—†ìœ¼ë©´ createdAtìœ¼ë¡œ ë¹„êµ
                        boolean orderViolation = false;
                        if (r.getProcessingSequence() != null && next.getProcessingSequence() != null) {
                            orderViolation = r.getProcessingSequence() > next.getProcessingSequence();
                        } else {
                            orderViolation = r.getCreatedAt().isAfter(next.getCreatedAt());
                        }
                        sample.put("orderViolation", orderViolation);
                    } else {
                        sample.put("orderViolation", false);
                    }

                    samples.add(sample);
                }
            }

            long endTime = System.currentTimeMillis();
            long duration = endTime - startTime;

            // 6. ì‘ë‹µ ë°ì´í„° êµ¬ì„±
            Map<String, Object> data = new HashMap<>();
            data.put("campaignId", campaignId);
            data.put("queryTimeMs", duration);

            // ë©”ì¸ ì§€í‘œ
            Map<String, Object> summary = new HashMap<>();
            summary.put("totalRecords", allRecords.size());
            summary.put("inversionCount", inversionCount);  // ì—­ì „ ìŒ ìˆ˜
            summary.put("totalPairs", totalPairs);  // ì „ì²´ ë¹„êµ ìŒ ìˆ˜
            summary.put("orderAccuracy", String.format("%.2f%%", orderAccuracy));
            summary.put("partitionCount", partitionGroups.size());
            data.put("summary", summary);

            data.put("partitionDistribution", partitionDistribution);
            data.put("partitionMismatches", partitionMismatches);
            data.put("samples", samples);

            // í•´ì„ ê°€ì´ë“œ
            Map<String, Object> interpretation = new HashMap<>();
            interpretation.put("orderAccuracy", "ì „ì—­ ìˆœì„œ ì¼ì¹˜ìœ¨ (Inversion Count ê¸°ë°˜)");
            interpretation.put("algorithm", "Merge Sort ê¸°ë°˜ O(n log n) ì—­ì „ ìŒ ê³„ì‚°");
            interpretation.put("guide", orderAccuracy >= 99.0 ? "ì™„ë²½í•œ ìˆœì„œ ë³´ì¥" :
                             orderAccuracy >= 95.0 ? "ë†’ì€ ìˆœì„œ ë³´ì¥" :
                             orderAccuracy >= 85.0 ? "ì¤‘ê°„ ìˆœì„œ ë³´ì¥" :
                             orderAccuracy >= 50.0 ? "ë‚®ì€ ìˆœì„œ ë³´ì¥ (ë³‘ë ¬ ì²˜ë¦¬ ì˜í–¥)" :
                             "ìˆœì„œ ë³´ì¥ ì—†ìŒ (ì™„ì „ ë³‘ë ¬ ì²˜ë¦¬)");
            interpretation.put("note", String.format("ì „ì²´ %,dìŒ ì¤‘ %,dìŒ ì—­ì „", totalPairs, inversionCount));
            data.put("interpretation", interpretation);

            log.info("ğŸ“Š ìˆœì„œ ë¶„ì„ ì™„ë£Œ - campaignId: {}, totalRecords: {}, partitions: {}, orderAccuracy: {:.2f}%, queryTime: {}ms",
                    campaignId, allRecords.size(), partitionGroups.size(), orderAccuracy, duration);

            return ResponseEntity.ok(ApiResponse.success(data));

        } catch (Exception e) {
            log.error("ğŸš¨ ìˆœì„œ ë¶„ì„ ì‹¤íŒ¨ - campaignId: {}", campaignId, e);
            return ResponseEntity.internalServerError()
                    .body(ApiResponse.fail("ìˆœì„œ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."));
        }
    }

    // ==================== Inversion Count ì•Œê³ ë¦¬ì¦˜ (Merge Sort ê¸°ë°˜) ====================

    /**
     * ì „ì—­ ìˆœì„œ ì—­ì „ ìŒ ê³„ì‚° (O(n log n))
     * - íƒ€ì„ìŠ¤íƒ¬í”„ ìˆœìœ¼ë¡œ ì •ë ¬ëœ processingSequence ë°°ì—´ì—ì„œ ì—­ì „ ìŒ ìˆ˜ë¥¼ ê³„ì‚°
     * - ì—­ì „ = ë¨¼ì € ë„ì°©í•œ ë©”ì‹œì§€ê°€ ë‚˜ì¤‘ì— ì²˜ë¦¬ëœ ê²½ìš°
     */
    private long countInversions(long[] arr) {
        long[] temp = arr.clone();
        return mergeSortAndCount(temp, 0, temp.length - 1);
    }

    private long mergeSortAndCount(long[] arr, int left, int right) {
        long count = 0;
        if (left < right) {
            int mid = left + (right - left) / 2;
            count += mergeSortAndCount(arr, left, mid);
            count += mergeSortAndCount(arr, mid + 1, right);
            count += mergeAndCount(arr, left, mid, right);
        }
        return count;
    }

    private long mergeAndCount(long[] arr, int left, int mid, int right) {
        int n1 = mid - left + 1;
        int n2 = right - mid;

        long[] leftArr = new long[n1];
        long[] rightArr = new long[n2];

        System.arraycopy(arr, left, leftArr, 0, n1);
        System.arraycopy(arr, mid + 1, rightArr, 0, n2);

        int i = 0, j = 0, k = left;
        long count = 0;

        while (i < n1 && j < n2) {
            if (leftArr[i] <= rightArr[j]) {
                arr[k++] = leftArr[i++];
            } else {
                arr[k++] = rightArr[j++];
                count += (n1 - i);  // ì—­ì „ ìŒ ì¹´ìš´íŠ¸
            }
        }

        while (i < n1) arr[k++] = leftArr[i++];
        while (j < n2) arr[k++] = rightArr[j++];

        return count;
    }
}
