package io.eventdriven.batchkafka.application.service;

import tools.jackson.core.JsonProcessingException;
import tools.jackson.databind.json.JsonMapper;
import io.eventdriven.batchkafka.api.exception.infrastructure.KafkaPublishException;
import io.eventdriven.batchkafka.api.exception.infrastructure.KafkaSerializationException;
import io.eventdriven.batchkafka.application.event.ParticipationEvent;
import lombok.RequiredArgsConstructor;
import lombok.extern.slf4j.Slf4j;
import org.springframework.kafka.core.KafkaTemplate;
import org.springframework.kafka.support.SendResult;
import org.springframework.stereotype.Service;

import java.util.concurrent.CompletableFuture;

@Slf4j
@Service
@RequiredArgsConstructor
public class ParticipationService {

    private final KafkaTemplate<String, String> kafkaTemplate;
    private final JsonMapper jsonMapper;

    private static final String TOPIC = "campaign-participation-topic";

    /**
     * ì„ ì°©ìˆœ ì°¸ì—¬ ìš”ì²­ ì²˜ë¦¬ (ë¹„ë™ê¸° + ì½œë°±)
     * - Kafkaë¡œ ì´ë²¤íŠ¸ ë°œí–‰
     * - ì „ì†¡ ê²°ê³¼ë¥¼ ë¹„ë™ê¸°ë¡œ í™•ì¸í•˜ì—¬ ì‹¤íŒ¨ ì‹œ ë¡œê¹… ë° ì•Œë¦¼
     */
    public void participate(Long campaignId, Long userId) {
        ParticipationEvent event = new ParticipationEvent(campaignId, userId);

        try {
            // 1. JSON ì§ë ¬í™”
            String message = jsonMapper.writeValueAsString(event);
            String key = String.valueOf(campaignId);

            // 2. Kafka ì „ì†¡ (ë¹„ë™ê¸° + ì½œë°±)
            CompletableFuture<SendResult<String, String>> future =
                    kafkaTemplate.send(TOPIC, key, message);

            // 3. ì „ì†¡ ê²°ê³¼ ì½œë°± ì²˜ë¦¬
            future.whenComplete((result, ex) -> {
                if (ex != null) {
                    // ì „ì†¡ ì‹¤íŒ¨
                    handleKafkaPublishFailure(campaignId, userId, message, ex);
                } else {
                    // ì „ì†¡ ì„±ê³µ
                    handleKafkaPublishSuccess(campaignId, userId, result);
                }
            });

        } catch (JsonProcessingException e) {
            // JSON ì§ë ¬í™” ì‹¤íŒ¨
            log.error("ğŸš¨ JSON ì§ë ¬í™” ì‹¤íŒ¨ - Campaign ID: {}, User ID: {}", campaignId, userId, e);
            throw new KafkaSerializationException(e);
        }
    }

    /**
     * Kafka ì „ì†¡ ì„±ê³µ ì²˜ë¦¬
     */
    private void handleKafkaPublishSuccess(Long campaignId, Long userId, SendResult<String, String> result) {
        log.info("âœ… Kafka ì „ì†¡ ì„±ê³µ - Campaign ID: {}, User ID: {}, Offset: {}, Partition: {}",
                campaignId,
                userId,
                result.getRecordMetadata().offset(),
                result.getRecordMetadata().partition());

        // TODO: ë©”íŠ¸ë¦­ ìˆ˜ì§‘ (Prometheus ë“±)
        // meterRegistry.counter("kafka.publish.success", "topic", TOPIC).increment();
    }

    /**
     * Kafka ì „ì†¡ ì‹¤íŒ¨ ì²˜ë¦¬
     */
    private void handleKafkaPublishFailure(Long campaignId, Long userId, String message, Throwable ex) {
        log.error("ğŸš¨ Kafka ì „ì†¡ ì‹¤íŒ¨ - Campaign ID: {}, User ID: {}, Message: {}",
                campaignId, userId, message, ex);

        // ìš´ì˜ì ì•Œë¦¼ (ì‹¤ì œ í™˜ê²½ì—ì„œëŠ” Slack, Email ë“±ìœ¼ë¡œ ì „ì†¡)
        log.error("ğŸ”” [ALERT] Kafka ì „ì†¡ ì‹¤íŒ¨ - ë°ì´í„° ì†ì‹¤ ìœ„í—˜! Campaign ID: {}, User ID: {}",
                campaignId, userId);

        // TODO: ì‹¤íŒ¨í•œ ë©”ì‹œì§€ë¥¼ ë³„ë„ ì €ì¥ (DB ë˜ëŠ” íŒŒì¼)
        // failureRepository.save(new KafkaFailureLog(campaignId, userId, message, ex.getMessage()));

        // TODO: ë©”íŠ¸ë¦­ ìˆ˜ì§‘
        // meterRegistry.counter("kafka.publish.failure", "topic", TOPIC).increment();

        // ì‚¬ìš©ìì—ê²ŒëŠ” ì¼ë°˜ì ì¸ ì˜¤ë¥˜ ë©”ì‹œì§€ë¥¼ ë˜ì§ (GlobalExceptionHandlerê°€ ì²˜ë¦¬)
        throw new KafkaPublishException(TOPIC, ex);
    }
}